{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FCV_Project_DataPrep.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1u8HOX_35HjdfV6t_pDf1DLwYnJBRA3eY","authorship_tag":"ABX9TyPCgyyL1vfLhbBGY7sm1BH2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gtYXdUl05GL0","colab_type":"code","outputId":"fd74f0f5-f188-4b8e-af70-0aa4eabee95f","executionInfo":{"status":"ok","timestamp":1587519009303,"user_tz":240,"elapsed":2919,"user":{"displayName":"Srujan Ganesh Shetty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHE-IjIb_Dieflsph3JZXFWv_-nAl9bKZqEleo=s64","userId":"11567554211584385208"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","import os\n","import sys\n","from keras.preprocessing import image\n","from keras.applications.vgg16 import VGG16\n","from keras.models import Model\n","from keras.applications.vgg16 import preprocess_input\n","np.set_printoptions(threshold=sys.maxsize)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6xcZjLr3Hb-w","colab_type":"code","colab":{}},"source":["def getFrames():\n","  video = cv2.VideoCapture(\"./000001_Short.mp4\")\n","  total = 0\n","  total = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n","  print(\"Total : %d\" %total)\n","  # video.set(1,82);\n","\n","  # ret, frame = video.read()\n","\n","  # cv2_imshow(frame)\n","\n","  # cv2.waitKey()\n","  video.release()\n","  cv2.destroyAllWindows()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8wRrvyUJwzI","colab_type":"code","colab":{}},"source":["def reduceVideo():\n","  cap = cv2.VideoCapture(\"./000001.mp4\")\n","  codec = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n","  framerate=25\n","  resolution=(int(cap.get(3)),int(cap.get(4)))\n","  VideoFileOutput=cv2.VideoWriter(\"000001_Short.mp4\",codec,framerate, resolution)\n","  count = 0\n","  while count < 100:\n","    count += 1\n","    success, frame = cap.read()\n","    if not success:\n","      break\n","    VideoFileOutput.write(frame)\n","  VideoFileOutput.release()        \n","  cap.release()\n","  cv2.destroyAllWindows()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8kIBmNaK_jz","colab_type":"code","colab":{}},"source":["def extractFeatures():\n","  model = VGG16(weights='imagenet', include_top=True)\n","  model.layers.pop()\n","\n","  # model.summary()  \n","\n","  # Load Yolo\n","  net = cv2.dnn.readNet(\"weights/yolov3-tiny.weights\", \"cfg/yolov3-tiny.cfg\")\n","  # net = cv2.dnn.readNet(\"cfg/yolov3-tiny.cfg\", \"weights/yolov3-tiny.weights\" )\n","  classes = []\n","  with open(\"coco.names\", \"r\") as f:\n","      classes = [line.strip() for line in f.readlines()]\n","  layer_names = net.getLayerNames()\n","  output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","  colors = np.random.uniform(0, 255, size=(len(classes), 4))\n","\n","  videos = os.listdir('./video/')\n","  ID = np.array([])\n","  labels = np.empty((0, 2))\n","  data = np.empty((0, 100, 20, 4096))\n","  det = np.empty((0, 100, 19, 4))\n","\n","  for video_name in videos:\n","    print(\"Processing video %s\" %video_name)\n","    ID = np.append(ID, np.array([video_name.split('.')[0]]))\n","    labels = np.vstack((labels, np.array([[0, 1]])))\n","    cap = cv2.VideoCapture('./video/' + video_name)\n","    det_temp = np.empty((0, 19, 4))\n","    frame_temp = np.empty((0, 20, 4096))\n","    frame_Count = 0\n","    while frame_Count < 100:\n","      frame_Count += 1\n","      border_temp = np.empty((0, 4))\n","      pixel_temp = np.empty((0, 4096))\n","      success, frame = cap.read()\n","      if not success:\n","        break\n","      height, width, channels = frame.shape\n","      # Detecting objects\n","      blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n","      net.setInput(blob)\n","      outs = net.forward(output_layers)\n","      # Showing informations on the screen\n","      class_ids = []\n","      confidences = []\n","      boxes = []\n","      for out in outs:\n","          for detection in out:\n","              scores = detection[5:]\n","              class_id = np.argmax(scores)\n","              confidence = scores[class_id]\n","              if confidence > 0.10:\n","                  # Object detected\n","                  center_x = int(detection[0] * width)\n","                  center_y = int(detection[1] * height)\n","                  w = int(detection[2] * width)\n","                  h = int(detection[3] * height)\n","                  # Rectangle coordinates\n","                  x = int(center_x - w / 2)\n","                  y = int(center_y - h / 2)\n","                  boxes.append([x, y, w, h])\n","                  confidences.append(float(confidence))\n","                  class_ids.append(class_id)\n","      indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.3)\n","\n","      img_path = 'temp.jpeg'\n","      cv2.imwrite(img_path, frame)      \n","      img = image.load_img(img_path, target_size=(224, 224))\n","      img_data = image.img_to_array(img)\n","      img_data = np.expand_dims(img_data, axis=0)\n","      img_data = preprocess_input(img_data)\n","\n","      extract_fc1_features = Model(input=model.input, output=model.get_layer('fc1').output)\n","      fc1_features = extract_fc1_features.predict(img_data)\n","      fc1_features = np.squeeze(fc1_features)\n","      # print(fc1_features.shape)\n","      pixel_temp = np.vstack((pixel_temp, fc1_features))      \n","\n","      # frame_crop = cv2.resize(frame, (64, 64))\n","      # frame_crop = cv2.cvtColor(frame_crop, cv2.COLOR_BGR2GRAY)\n","      # frame_crop = frame_crop / 255      \n","      # pixel_temp = np.vstack((pixel_temp, frame_crop.flatten()))\n","\n","      for i in range(len(boxes)):\n","          if i in indexes:\n","              x1, y1, w, h = boxes[i]            \n","              x2 = x1 + w\n","              y2 = y1 + h\n","              border_temp = np.vstack((border_temp, np.array([[x1, y1, x2, y2]])))\n","              # cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)  \n","              crop = frame[y1:y2, x1:x2]\n","              cv2.imwrite(img_path, crop)      \n","              img = image.load_img(img_path, target_size=(224, 224))\n","              img_data = image.img_to_array(img)\n","              img_data = np.expand_dims(img_data, axis=0)\n","              img_data = preprocess_input(img_data)\n","\n","              extract_fc1_features = Model(input=model.input, output=model.get_layer('fc1').output)\n","              fc1_features = extract_fc1_features.predict(img_data)\n","              fc1_features = np.squeeze(fc1_features)\n","              # print(fc1_features.shape)\n","              pixel_temp = np.vstack((pixel_temp, fc1_features))  \n","\n","              # try:                \n","              #   crop = cv2.resize(crop, (64, 64))\n","              # except:\n","              #   cv2_imshow(frame)\n","              #   break\n","              # crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n","              # crop = crop / 255\n","              # pixel_temp = np.vstack((pixel_temp, crop.flatten()))\n","      while border_temp.shape[0] < 19:\n","        border_temp = np.vstack((border_temp, np.zeros(4)))\n","      while pixel_temp.shape[0] < 20:\n","        pixel_temp = np.vstack((pixel_temp, np.zeros(4096)))\n","      key = cv2.waitKey(1)\n","      if key == 27:\n","          break    \n","      det_temp = np.vstack((det_temp, np.array([border_temp])))\n","      frame_temp = np.vstack((frame_temp, np.array([pixel_temp])))    \n","    cap.release()\n","    cv2.destroyAllWindows()  \n","    det = np.vstack((det, np.array([det_temp])))\n","    data = np.vstack((data, np.array([frame_temp])))  \n","\n","    if data.shape[0] == 10:\n","      break\n","  \n","  return data, det, labels, ID\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sxxKCjYfSxV5","colab_type":"code","colab":{}},"source":["data, det, labels, ID = extractFeatures()\n","det = det.astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KaJKZ5WytX-D","colab_type":"code","colab":{}},"source":["np.savez(\"data.npz\", data=data, det=det, labels=labels, ID=ID)"],"execution_count":0,"outputs":[]}]}